# kafka topic where the logs will be sent
fuse_kafka_topic=["logs"]
# directories fuse_kafka will listen to (launch script will try to
# create them if they don't exist)
# fuse_kafka will also ignore duplicates in absolute path in this list
fuse_kafka_directories=["/tmp/fuse-kafka-test"]
# addresses of zookeepers pointing to kafka brokers of the form
# "zk1=port,zk2:port,zk3:port"
# if this is defined, fuse_kafka_brokers will be ignored
fuse_kafka_zookeepers=["127.0.0.1:2181"]
# addresses of kafka brokers of the form
# "broker1:port,broker2:port,broker3:port"
#fuse_kafka_brokers=["localhost:9092"]
# logstash-like fields which will be added to each event
# for example, this will allow to identify where the event is
# from
fuse_kafka_fields={"hostname": "test"}
# logstash-like tags to add to each events
# for example this will mark this event as a test event
fuse_kafka_tags=["test"]
# optional list of directories to stop listening to when fuse kafka
# goes to sleep
fuse_kafka_sleep=["/tmp/fuse-kafka-test"]
# you can optionnaly limit the bandwidth used by fuse_kafka
# if a file takes more than this bandwidth, its data won't be sent
# to kafka
# this array may be supplied two parameters:
#   - quota (the wanted quota in bytes per second)
#   - time_queue size: the maximum number of files the system tracks at any
#   given time (optional, default being 20)
fuse_kafka_quota=[500000]
# default input plugin is overlay (which is fuse),
# but you can select another one, for example to use inotify:
fuse_kafka_input=["inotify"]
#fuse_kafka_input=["example"]
#fuse_kafka_input=["overlay"]
